{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1.2 - Clustering Load Profiles\n",
    "\n",
    "Load profiling is a crucial aspect of energy consumption analysis that involves collecting and analyzing data on the energy usage of a system or building. Clustering, on the other hand, is a machine learning technique used to group similar data points together.\n",
    "\n",
    "In this exercise session, we will learn how to use Python to cluster load profiles. We will start by exploring what load profiles are, how they are collected and why they are important. Next, we will delve into the theory behind clustering and its applications in load profiling. We will then work through a step-by-step guide to using Python's scikit-learn library to perform load profile clustering.\n",
    "\n",
    "By the end of this exercise session, you will have a good understanding of load profiles, clustering techniques and how to apply these techniques in Python to perform load profile clustering. You will also be able to interpret the results of the clustering and use them to make informed decisions about energy consumption management. So, let's get started!\n",
    "\n",
    "### Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"data/LoadTimeSeriesData.csv\", parse_dates=['timestamp'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: use one of the previous nas replacement methods to fill nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['power'].interpolate(method='spline', inplace=True, order=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform load profiles clustering, we need to re-organize our dataset into a MxN matrix where:\n",
    "* M is the number of days in our dataset\n",
    "* N is the frequency of our timeseries (i.e. hour)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Assign new columns for data and hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['timestamp'].dt.date\n",
    "df['hour'] = df['timestamp'].dt.hour"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: generate the MxN matrix using the new columns.\n",
    "\n",
    "*hint*: use the pivot function of pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix = df.pivot(index='date', columns='hour', values='power')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: perfrom clustering using KMeans method. Select a value for K (desired number of clusters). Then extract the cluster labels from the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering\n",
    "K = 5\n",
    "kmeans = KMeans(n_clusters=K, random_state=0).fit(df_matrix)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: add the labels to the original dataframe (timeseries) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cluster labels to the original dataset\n",
    "df['cluster'] = np.repeat(labels, 24)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centroids\n",
    "\n",
    "In the context of load profiles clustering, centroids are usually represented as the average load profile of the cluster.\n",
    "\n",
    "**Task**: evaluate the average profile (i.e. evaluate the mean of power for each cluster and each hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new DataFrame with the average power for each hour of the day and for each cluster\n",
    "centroids = df.groupby(['cluster', 'hour'])['power'].mean().reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: plot the load profiles for each cluster and the centroid.\n",
    "\n",
    "*hint*: employ the code of the previous lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating load profiles\n",
    "g = sns.FacetGrid(data=df, col='cluster', hue='date', col_wrap=3, height=3, aspect=2, sharey=False)\n",
    "g.map(sns.lineplot, 'hour', 'power', color='gray')\n",
    "\n",
    "# adding average values\n",
    "for ax, cluster in zip(g.axes.flatten(), centroids['cluster'].unique()):\n",
    "    sns.lineplot(x='hour', y='power', data=centroids[centroids['cluster'] == cluster], color='r', ax=ax, label='Profilo medio', legend=False)\n",
    "    ax.set_ylim(bottom=0, top=df['power'].max())\n",
    "    ax.set_xticks(range(0, 24))\n",
    "    ax.grid(True, linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering\n",
    "K = 3\n",
    "kmeans = KMeans(n_clusters=K, random_state=0).fit(df_matrix)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Add the cluster labels to the original dataset\n",
    "df['cluster'] = np.repeat(labels, 24)\n",
    "\n",
    "# creating a new DataFrame with the average power for each hour of the day and for each cluster\n",
    "centroids = df.groupby(['cluster', 'hour'])['power'].mean().reset_index()\n",
    "\n",
    "# generating load profiles\n",
    "g = sns.FacetGrid(data=df, col='cluster', hue='date', col_wrap=3, height=3, aspect=2, sharey=False)\n",
    "g.map(sns.lineplot, 'hour', 'power', color='gray')\n",
    "\n",
    "# adding average values\n",
    "for ax, cluster in zip(g.axes.flatten(), centroids['cluster'].unique()):\n",
    "    sns.lineplot(x='hour', y='power', data=centroids[centroids['cluster'] == cluster], color='r', ax=ax, label='Profilo medio', legend=False)\n",
    "    ax.set_ylim(bottom=0, top=df['power'].max())\n",
    "    ax.set_xticks(range(0, 24))\n",
    "    ax.grid(True, linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: Hierarchical clustering\n",
    "\n",
    "Agglomerative clustering is a popular hierarchical clustering method used to group similar data points into clusters. It works by initially treating each data point as its own cluster and then iteratively merging the closest clusters until only one cluster containing all data points remains. The merging process is guided by a linkage method that determines how the distance between two clusters is measured.\n",
    "\n",
    "There are several linkage methods used in agglomerative clustering, each with its own advantages and disadvantages.\n",
    "\n",
    "The **single** linkage method, also known as the nearest-neighbor method, calculates the distance between the closest two data points in each cluster and merges the two clusters with the smallest distance. This method tends to produce long, narrow clusters and can be sensitive to noise and outliers.\n",
    "\n",
    "The **complete** linkage method, also known as the farthest-neighbor method, calculates the distance between the furthest two data points in each cluster and merges the two clusters with the largest distance. This method tends to produce compact, spherical clusters but can also be sensitive to noise and outliers.\n",
    "\n",
    "The **average** linkage method calculates the average distance between all pairs of data points in each cluster and merges the two clusters with the smallest average distance. This method can be less sensitive to noise and outliers than the single and complete linkage methods and tends to produce more balanced clusters.\n",
    "\n",
    "The **Ward** linkage method minimizes the increase in variance of the clusters resulting from merging them. It tends to produce compact, spherical clusters of similar size and is less sensitive to noise and outliers than the other linkage methods.\n",
    "\n",
    "Overall, the choice of linkage method in agglomerative clustering depends on the nature of the data and the goals of the analysis. Each method has its own strengths and weaknesses, and selecting the appropriate method can lead to more meaningful and accurate clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None, linkage=\"single\").fit(df_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "# plot the top (p) levels of the dendrogram\n",
    "plot_dendrogram(model, truncate_mode=\"level\", p=4)\n",
    "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Analyze different *linkage methods* and *number of K* to understand the differences between the different approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering\n",
    "K = 5\n",
    "linkage_method = \"ward\" # \"complete\", \"single\", \"average\"\n",
    "model = AgglomerativeClustering(distance_threshold=None, n_clusters=K, linkage=linkage_method).fit(df_matrix)\n",
    "labels = model.labels_\n",
    "\n",
    "# Add the cluster labels to the original dataset\n",
    "df['cluster'] = np.repeat(labels, 24)\n",
    "\n",
    "# creating a new DataFrame with the average power for each hour of the day and for each cluster\n",
    "centroids = df.groupby(['cluster', 'hour'])['power'].mean().reset_index()\n",
    "\n",
    "# generating load profiles\n",
    "g = sns.FacetGrid(data=df, col='cluster', hue='date', col_wrap=3, height=3, aspect=2, sharey=False)\n",
    "g.map(sns.lineplot, 'hour', 'power', color='gray')\n",
    "\n",
    "# adding average values\n",
    "for ax, cluster in zip(g.axes.flatten(), centroids['cluster'].unique()):\n",
    "    sns.lineplot(x='hour', y='power', data=centroids[centroids['cluster'] == cluster], color='r', ax=ax, label='Profilo medio', legend=False)\n",
    "    ax.set_ylim(bottom=0, top=df['power'].max())\n",
    "    ax.set_xticks(range(0, 24))\n",
    "    ax.grid(True, linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: Classifying cluster labes through supervised model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
