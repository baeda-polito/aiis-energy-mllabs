{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLOPS tools: Mlflow\n",
    "\n",
    "MLflow is an open-source platform for managing the end-to-end machine learning lifecycle. It was developed by Databricks and is now maintained by the Linux Foundation. MLflow provides a set of tools for tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\n",
    "\n",
    "MLflow is designed to help data scientists and machine learning engineers manage the complexity of the machine learning lifecycle. With MLflow, you can:\n",
    "\n",
    "Track experiments: MLflow allows you to log parameters, metrics, and artifacts for each experiment, making it easy to reproduce results and compare different models.\n",
    "\n",
    "Package code: MLflow allows you to package code into reproducible runs, making it easy to share and deploy models across different environments.\n",
    "\n",
    "Share and deploy models: MLflow provides tools for sharing models with other members of your team, as well as for deploying models to different production environments.\n",
    "\n",
    "MLflow is built on top of popular machine learning libraries like scikit-learn, TensorFlow, and PyTorch, so you can use your favorite tools and workflows with MLflow. It also integrates with a variety of data storage and compute platforms, including Amazon S3, Azure Blob Storage, and Databricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate some sample data\n",
    "df = pd.read_csv(\"data/LoadTimeSeriesData_case1.csv\", parse_dates=['timestamp'])\n",
    "df['power'].interpolate(method='spline', inplace=True, order=3)\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df_matrix = df.pivot(index='date', columns='hour', values='power')\n",
    "\n",
    "# Set up the mlflow experiment\n",
    "mlflow.set_experiment(\"KMeans Clustering\")\n",
    "\n",
    "# Define the clustering parameters\n",
    "k = 5\n",
    "\n",
    "# Train the k-means model\n",
    "with mlflow.start_run(run_name=\"kmeans_model\"):\n",
    "    \n",
    "    # Fit the model\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(df_matrix)\n",
    "    \n",
    "    # Evaluate the model using the Davies-Bouldin index and Silhouette index\n",
    "    db_index = davies_bouldin_score(df_matrix, kmeans.labels_)\n",
    "    sil_score = silhouette_score(df_matrix, kmeans.labels_)\n",
    "    \n",
    "    # Log the metrics to mlflow\n",
    "    mlflow.log_metric(\"Davies-Bouldin Index\", db_index)\n",
    "    mlflow.log_metric(\"Silhouette Score\", sil_score)\n",
    "    \n",
    "    # Log the hyperparameters to mlflow\n",
    "    mlflow.log_param(\"k\", k)\n",
    "    \n",
    "    # Log the model to mlflow\n",
    "    mlflow.sklearn.log_model(kmeans, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import calmap\n",
    "from matplotlib.colors import ListedColormap, Normalize\n",
    "\n",
    "# Generate some sample data\n",
    "df = pd.read_csv(\"data/LoadTimeSeriesData_case1.csv\", parse_dates=['timestamp'])\n",
    "df['power'].interpolate(method='spline', inplace=True, order=3)\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df_matrix = df.pivot(index='date', columns='hour', values='power')\n",
    "\n",
    "# Set up the mlflow experiment\n",
    "mlflow.set_experiment(\"KMeans Clustering\")\n",
    "\n",
    "# Define the clustering parameters\n",
    "k = 4\n",
    "\n",
    "# Train the k-means model\n",
    "with mlflow.start_run(run_name=\"kmeans_model\"):\n",
    "    \n",
    "    # Fit the model\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(df_matrix)\n",
    "    labels = kmeans.labels_\n",
    "    cluster_counts = np.unique(labels, return_counts=True)\n",
    "    df['cluster'] = np.repeat(labels, 24)\n",
    "    centroids = df.groupby(['cluster', 'hour'])['power'].mean().reset_index()\n",
    "    \n",
    "    # Evaluate the model using the Davies-Bouldin index and Silhouette index\n",
    "    db_index = davies_bouldin_score(df_matrix, kmeans.labels_)\n",
    "    sil_score = silhouette_score(df_matrix, kmeans.labels_)\n",
    "    \n",
    "    # Log the metrics to mlflow\n",
    "    mlflow.log_metric(\"Davies-Bouldin Index\", db_index)\n",
    "    mlflow.log_metric(\"Silhouette Score\", sil_score)\n",
    "    \n",
    "    # Log the hyperparameters to mlflow\n",
    "    mlflow.log_param(\"k\", k)\n",
    "    \n",
    "    # Log the model to mlflow\n",
    "    mlflow.sklearn.log_model(kmeans, \"model\")\n",
    "\n",
    "    #\n",
    "    # generating load profiles\n",
    "    g = sns.FacetGrid(data=df, col='cluster', hue='date', col_wrap=3, height=3, aspect=2, sharey=False)\n",
    "    g.map(sns.lineplot, 'hour', 'power', color='gray')\n",
    "\n",
    "    # adding average values\n",
    "    i = 0\n",
    "    for ax, cluster in zip(g.axes.flatten(), centroids['cluster'].unique()):\n",
    "        sns.lineplot(x='hour', y='power', data=centroids[centroids['cluster'] == cluster], color='r', ax=ax, label='Profilo medio', legend=False)\n",
    "        ax.set_ylim(bottom=0, top=df['power'].max())\n",
    "        ax.set_xticks(range(0, 24))\n",
    "        ax.grid(True, linestyle='--')\n",
    "\n",
    "        cluster_counts_str = 'Count: ' + str(cluster_counts[1][i])\n",
    "        ax.text(0.05, 0.95, cluster_counts_str, transform=ax.transAxes, fontsize=10, verticalalignment='top')\n",
    "        i += 1\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    mlflow.log_figure(g.fig, 'graph/centroinds.png')\n",
    "\n",
    "    # calendar visualization\n",
    "    cal_data = pd.DataFrame({'cluster': labels}, index=pd.to_datetime(df_matrix.index))\n",
    "    colors = sns.color_palette(\"husl\", k)\n",
    "    hex_colors = ['#{:02x}{:02x}{:02x}'.format(int(color[0]*255), int(color[1]*255), int(color[2]*255)) for color in colors]\n",
    "    cmap = ListedColormap(hex_colors)\n",
    "\n",
    "    fig, ax = calmap.calendarplot(cal_data['cluster'], cmap=cmap, \n",
    "                                fillcolor='grey', linewidth=0.5, fig_kws=dict(figsize=(12, 4)), monthticks=3, daylabels='MTWTFSS')\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=Normalize(vmin=0, vmax=k-1))\n",
    "    sm.set_array([])\n",
    "    cax = fig.add_axes([0.3, 0.9, 0.4, 0.05])\n",
    "    cb = plt.colorbar(sm, cax=cax, orientation='horizontal')\n",
    "    cb.set_label('Cluster')\n",
    "    cb.set_ticks(cal_data['cluster'].unique())\n",
    "    cb.set_ticklabels(cal_data['cluster'].unique())\n",
    "\n",
    "    mlflow.log_figure(fig, 'graph/calendar_map.png')\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
