{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.1 Internal Energy Benchmarking Process\n",
    "\n",
    "Welcome to this Python exercise session, where we will explore how to develop an energy benchmarking process for a single building using Python programming language. This exercise is designed to provide hands-on experience in data processing, analysis, and visualization techniques commonly used in energy benchmarking. By the end of the session, you will have gained practical knowledge in handling energy consumption data and implementing benchmarking analysis for a building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and load the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the power dataset\n",
    "energy_data = pd.read_csv(\"data/energyData.csv\", parse_dates=[\"timestamp\"], index_col=\"timestamp\")\n",
    "\n",
    "# Load the weather dataset\n",
    "weather_data = pd.read_csv(\"data/weatherData.csv\", parse_dates=[\"timestamp\"], index_col=\"timestamp\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Task Assignment**: Merge Energy and Temperature Datasets and Perform Feature Engineering\n",
    "\n",
    "Objective: In this task, you will merge two datasets containing energy consumption and temperature data and perform feature engineering to create additional variables that can be used in the subsequent analysis.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Merge the energy and temperature datasets:\n",
    "    - Perform an inner join on the index to merge the two DataFrames into a single DataFrame named data. This will ensure that only the rows with matching timestamps in both datasets are included in the merged dataset.\n",
    "- Perform feature engineering by creating new variables from the timestamp index:\n",
    "    - Create a new column named \"hour\" in the data DataFrame by extracting the hour from the DateTime index.\n",
    "    - Create a new column named \"day_of_week\" in the data DataFrame by extracting the day of the week from the DateTime index (Monday = 0, Sunday = 6).\n",
    "\n",
    "After completing this task, you should have a merged dataset containing energy consumption, temperature, and additional time-related variables (hour and day_of_week) in a single DataFrame. This enriched dataset will be used for further analysis, such as developing machine learning models for predicting energy consumption or evaluating the building's energy performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the energy and temperature datasets\n",
    "data = \n",
    "\n",
    "# Feature engineering\n",
    "data[\"hour\"] = \n",
    "data[\"day_of_week\"] = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Task Assignment**: Plot the *power* timeseries. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a function called replace_outliers_na that detects and replaces outliers in a specific column of a given dataset with NaN values. It uses the Interquartile Range (IQR) method for outlier detection.\n",
    "\n",
    "Here's a step-by-step description of the code:\n",
    "\n",
    "- Define the function replace_outliers_na with three input arguments: data (Pandas DataFrame), column (name of the column to process), and multiplier (default value is set to 1.5).\n",
    "\n",
    "- Calculate the first quartile (Q1) and the third quartile (Q3) of the given column using the quantile method of the Pandas DataFrame. Q1 corresponds to the 25th percentile, and Q3 corresponds to the 75th percentile.\n",
    "\n",
    "- Calculate the Interquartile Range (IQR) by subtracting Q1 from Q3. The IQR represents the range of the middle 50% of the data.\n",
    "\n",
    "- Calculate the lower and upper bounds for outlier detection. This is done by subtracting multiplier times IQR from Q1 for the lower bound and adding multiplier times IQR to Q3 for the upper bound. The default multiplier value is 1.5, which is commonly used for detecting mild outliers.\n",
    "\n",
    "- Create a Boolean mask for the rows in the DataFrame where the values in the specified column are either below the lower bound or above the upper bound. This mask will be used to identify the outliers in the dataset.\n",
    "\n",
    "- Use the .loc indexer with the Boolean mask to replace the outlier values in the specified column with NaN values. This operation is performed in-place on the input DataFrame.\n",
    "\n",
    "- Return the DataFrame with outliers replaced by NaN values.\n",
    "\n",
    "- Call the replace_outliers_na function with the input DataFrame (e.g., data) and the target column (e.g., 'power') to process. The function is called on a copy of the DataFrame to avoid modifying the original dataset.\n",
    "\n",
    "By using this function, outliers in the specified column are replaced with NaN values, allowing for further processing or filtering of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier detection\n",
    "\n",
    "def replace_outliers_na(data, column, multiplier=1.5):\n",
    "    # Calculate the first and third quartiles (Q1 and Q3)\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    \n",
    "    # Calculate the IQR\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Calculate the lower and upper bounds for outliers\n",
    "    lower_bound = Q1 - multiplier * IQR\n",
    "    upper_bound = Q3 + multiplier * IQR\n",
    "    \n",
    "    # Filter the dataset to remove the outliers\n",
    "    mask = (data[column] < lower_bound) | (data[column] > upper_bound)\n",
    "    data.loc[mask, column] = np.nan\n",
    "\n",
    "    return data\n",
    "\n",
    "data = replace_outliers_na(data.copy(), 'power')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Task Assignment**: Print the amount of nas values in the columns **power** and **airTemperature**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Task Assignment**: Remove Rows with NaN Values in the Power Column\n",
    "\n",
    "Remove rows with NaN values in the 'power' column:\n",
    "\n",
    "- Use the dropna() method on the DataFrame with the subset parameter set to ['power']. This will remove all rows where the 'power' column contains NaN values.\n",
    "- Assign the resulting DataFrame back to the variable data to store the updated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Task Assignment**: Perform Train-Test Split on the Dataset\n",
    "\n",
    "Perform the train-test split based on date ranges:\n",
    "\n",
    "- Create a variable called train and assign it the subset of the DataFrame for the date range from January 1, 2017, to October 31, 2017. Use the DateTime index to slice the DataFrame accordingly.\n",
    "- Create a variable called test and assign it the subset of the DataFrame for the date range from November 1, 2017, to December 31, 2017. Use the DateTime index to slice the DataFrame accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train = \n",
    "test = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code separates the features (independent variables) and the target variable (dependent variable) for both the training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(\"power\", axis=1)\n",
    "y_train = train[\"power\"]\n",
    "X_test = test.drop(\"power\", axis=1)\n",
    "y_test = test[\"power\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = RandomForestRegressor()  # You can replace this with other models from scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Task Assignment**: Implement Mean Absolute Percentage Error (MAPE) Function\n",
    "\n",
    "Objective: In this task, you will implement a function to calculate the Mean Absolute Percentage Error (MAPE) metric for evaluating the performance of a regression model.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Define a function called mean_absolute_percentage_error with two input arguments: y_true (true target values) and y_pred (predicted target values).\n",
    "\n",
    "In the function, calculate the MAPE by following these steps:\n",
    "\n",
    "- Compute the absolute difference between y_true and y_pred.\n",
    "- Divide the absolute difference by the true target values (y_true).\n",
    "- Compute the mean of the resulting values.\n",
    "- Multiply the mean by 100 to get the percentage error.\n",
    "- Return the calculated MAPE value.\n",
    "\n",
    "After completing this task, you should have a function that calculates the Mean Absolute Percentage Error, which can be used to evaluate the performance of regression models on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **Task Assignment**: Fit and Predict with a Machine Learning Model\n",
    "\n",
    "Train the machine learning model on the training dataset and make predictions on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "\n",
    "y_pred = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **Task Assignment**: Calculate and Print Evaluation Metrics\n",
    "\n",
    "Objective: In this task, you will compute and display the Mean Absolute Percentage Error (MAPE), Mean Absolute Error (MAE), and Mean Squared Error (MSE) for the model's predictions on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = \n",
    "mae = \n",
    "mse = \n",
    "\n",
    "print()\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **Task Assignment**: Visualize Actual and Predicted Power Values\n",
    "\n",
    "Objective: In this task, you will create a line plot to visualize the actual and predicted power values for both the training and testing datasets, showing the performance of the internal energy benchmarking model.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Generate predictions for the training dataset using the trained model.\n",
    "- Create a line plot with separate lines for actual and predicted power values in the training and testing datasets.\n",
    "- Customize the plot with appropriate axis labels, title, and legend.\n",
    "- Display the plot to visualize the model's performance in predicting power consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plot with predictions and real values for both training and testing\n",
    "y_train_pred = \n",
    "\n",
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a histogram to visualize the distribution of errors for both the training and testing datasets in the internal energy benchmarking model.\n",
    "\n",
    "- It calculates the errors for the training dataset (train_errors) and testing dataset (test_errors) by subtracting the predicted values from the actual values.\n",
    "- It initializes a new figure with a specified size using plt.figure().\n",
    "- The sns.histplot() function from the Seaborn library is used to create histograms for both training and testing errors. The kde=True argument adds a kernel density estimate (KDE) curve to the histograms.\n",
    "- The histograms are plotted with different colors and labels to distinguish between training and testing errors.\n",
    "- The plot is customized with axis labels, a title, and a legend.\n",
    "- Finally, the plot is displayed using plt.show(), allowing you to visualize and compare the error distributions for the training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with the distribution of the errors for both training and testing\n",
    "train_errors = y_train - y_train_pred\n",
    "test_errors = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(train_errors, kde=True, color=\"blue\", label=\"Train Errors\")\n",
    "sns.histplot(test_errors, kde=True, color=\"red\", label=\"Test Errors\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Internal Energy Benchmarking: Error Distribution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines a function named \"prediction_intervals\" that takes four inputs: y_true_train, y_pred_train, y_pred_test, and alpha.\n",
    "\n",
    "The function calculates the prediction intervals for a regression model. Specifically, it calculates the upper and lower bounds of the confidence interval for the predicted values.\n",
    "\n",
    "To do this, the function first calculates the errors between the true and predicted values of the training data. It then calculates the standard deviation of these errors using NumPy's std function.\n",
    "\n",
    "The function then calculates the z-score for the given alpha level using the percent-point function (ppf) from the normal distribution in the scipy.stats module.\n",
    "\n",
    "Finally, it calculates the upper and lower bounds of the prediction interval by adding and subtracting the product of the z-score and the standard deviation of the errors from the predicted test values.\n",
    "\n",
    "The function returns the lower and upper bounds of the prediction interval, which are assigned to the variables lower_bounds and upper_bounds, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def prediction_intervals(y_true_train, y_pred_train, y_pred_test, alpha=0.95):\n",
    "    errors = y_true_train - y_pred_train\n",
    "    std_errors = np.std(errors)\n",
    "    z_score = stats.norm.ppf(1 - (1 - alpha) / 2)\n",
    "    \n",
    "    lower_bounds = y_pred_test - z_score * std_errors\n",
    "    upper_bounds = y_pred_test + z_score * std_errors\n",
    "    \n",
    "    return lower_bounds, upper_bounds\n",
    "\n",
    "lower_bounds, upper_bounds = prediction_intervals(y_train, y_train_pred, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code creates a plot to visualize the actual test values, predicted test values, and prediction intervals for a regression model.\n",
    "\n",
    "It first creates a new figure with a specific size using the plt.figure() function.\n",
    "\n",
    "Then, it plots the actual test values and predicted test values against the dates of the test data using the plt.plot() function.\n",
    "\n",
    "Next, it fills the area between the lower and upper bounds of the prediction intervals with a gray color and an alpha (transparency) of 0.5 using the plt.fill_between() function. This indicates the range of possible error in the predicted values.\n",
    "\n",
    "The plot's x-axis is labeled as \"Date,\" and the y-axis is labeled as \"Power.\" The title of the plot is \"Internal Energy Benchmarking: Actual vs. Predicted Power.\"\n",
    "\n",
    "Finally, a legend is added to the plot using the plt.legend() function to indicate the meaning of each line in the plot. The plot is displayed using the plt.show() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(test.index, y_test, label=\"Real Values\")\n",
    "plt.plot(test.index, y_pred, label=\"Estimated Values\")\n",
    "plt.fill_between(test.index, lower_bounds, upper_bounds, color=\"gray\", alpha=0.5, label=\"Error\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.title(\"Internal Energy Benchmarking: Real vs. Estimated Power\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code calculates the underconsumption of energy in the testing dataset and its percentage with respect to the total energy consumption in the internal energy benchmarking context.\n",
    "\n",
    "- It calculates the underconsumption by subtracting the actual power consumption (test['power']) from the lower bounds of the confidence intervals (lower_bounds), storing the result in the underconsumption column of the test DataFrame.\n",
    "- The clip() function is used to replace any negative values in the underconsumption column with 0, as negative underconsumption values do not make sense in this context.\n",
    "- It calculates the total underconsumption by summing the underconsumption column, rounding the result to one decimal place.\n",
    "- It calculates the total energy consumption by summing the power column, rounding the result to one decimal place.\n",
    "- The underconsumption percentage is calculated by dividing the total underconsumption by the total energy consumption and multiplying by 100, rounding the result to two decimal places.\n",
    "- Finally, the total underconsumption and its percentage are printed out for further analysis and interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['underconsumption'] = lower_bounds - test['power']\n",
    "test['underconsumption'] = test['underconsumption'].clip(lower=0)\n",
    "total_underconsumption = np.round(test['underconsumption'].sum(), 1)\n",
    "total_consumption = np.round(test['power'].sum(), 1)\n",
    "underconsumption_percentage = np.round(total_underconsumption/total_consumption*100, 2)\n",
    "print(f'Total underconsumption identified: {total_underconsumption} kWh')\n",
    "print(f'Percentage of underconsumption over total: {underconsumption_percentage} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing for overconsumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['overconsumption'] = test['power'] - upper_bounds\n",
    "test['overconsumption'] = test['overconsumption'].clip(lower=0)\n",
    "total_overconsumption = np.round(test['overconsumption'].sum(), 1)\n",
    "overconsumtion_percentage = np.round(total_overconsumption/total_consumption*100, 2)\n",
    "print(f'Total overconsumption identified: {total_overconsumption} kWh')\n",
    "print(f'Percentage of overconsumption over total: {overconsumtion_percentage} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code groups the dataset by date, calculates the sum of the underconsumption column for each date, and creates a new dataframe called underconsumption_day with the date as the index and the sum of underconsumption for each date as the value.\n",
    "\n",
    "The next lines of code create a visualization of the underconsumption data using a calendar heatmap. The calmap library is used to create the heatmap, and the yearplot function is used to create the visualization for the year 2017. The heatmap shows the amount of underconsumption for each day of the year, with warmer colors indicating higher values and cooler colors indicating lower values.\n",
    "\n",
    "Finally, the code adds a title to the visualization, creates a colorbar to show the range of values, and displays the visualization on the screen. Overall, this code snippet is an example of how to use Python to perform data processing and create informative visualizations of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calmap\n",
    "import matplotlib as mpl\n",
    "\n",
    "test['date'] = test.index.date\n",
    "underconsumption_day = test.groupby('date')['underconsumption'].sum().reset_index()\n",
    "underconsumption_day['date'] = pd.to_datetime(underconsumption_day['date'])\n",
    "underconsumption_day = underconsumption_day.set_index('date')\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "calmap.yearplot(underconsumption_day['underconsumption'], year=2017, cmap='coolwarm', fillcolor='white')\n",
    "plt.title(\"Underconsumption [kWh]\")\n",
    "cmap = mpl.cm.coolwarm\n",
    "norm = mpl.colors.Normalize(vmin=underconsumption_day['underconsumption'].min(), vmax=underconsumption_day['underconsumption'].max())\n",
    "cax = plt.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap), orientation='horizontal', pad=0.05)\n",
    "cax.set_label(\"Underconsumption\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing as before for overconsumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overconsumption_day = test.groupby('date')['overconsumption'].sum().reset_index()\n",
    "overconsumption_day['date'] = pd.to_datetime(overconsumption_day['date'])\n",
    "overconsumption_day = overconsumption_day.set_index('date')\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "calmap.yearplot(overconsumption_day['overconsumption'], year=2017, cmap='coolwarm', fillcolor='white')\n",
    "plt.title(\"Overconsumption [kWh]\")\n",
    "cmap = mpl.cm.coolwarm\n",
    "norm = mpl.colors.Normalize(vmin=overconsumption_day['overconsumption'].min(), vmax=overconsumption_day['overconsumption'].max())\n",
    "cax = plt.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap), orientation='horizontal', pad=0.05)\n",
    "cax.set_label(\"Overconsumption\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells create a plot to visualize the actual power consumption, estimated power consumption, and the benchmark estimation interval for a specific date, \"2017-12-06\".\n",
    "\n",
    "- First, it adds the lower_bounds, upper_bounds, and power_pred (predicted power) columns to the test DataFrame.\n",
    "\n",
    "- Next, it creates a subset of the test DataFrame containing only data for the date \"2017-12-06\" and assigns it to the test_subset variable.\n",
    "\n",
    "- It then initializes a new plot with a size of 15 x 6 inches.\n",
    "\n",
    "- The actual power consumption is plotted as a line plot using the test_subset.power values.\n",
    "\n",
    "- The estimated power consumption is plotted as another line plot using the test_subset.power_pred values.\n",
    "\n",
    "- The benchmark estimation interval is displayed as a shaded area between the lower_bounds and upper_bounds using the fill_between() function. The shading is in gray with 50% transparency (alpha=0.5).\n",
    "\n",
    "- The x-axis is labeled as \"Date\" and the y-axis is labeled as \"Power\".\n",
    "\n",
    "- The plot title is set to \"2017-12-06: Real vs Benchmark\".\n",
    "\n",
    "- A legend is added to the plot to identify the different lines and the shaded area.\n",
    "\n",
    "- Finally, the plot is displayed using the plt.show() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['lower_bounds'] = lower_bounds\n",
    "test['upper_bounds'] = upper_bounds\n",
    "test['power_pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset = test[\"2017-12-06\"]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(test_subset.index, test_subset.power, label=\"Actual Consumption\")\n",
    "plt.plot(test_subset.index, test_subset.power_pred, label=\"Estimated Consumption\")\n",
    "plt.fill_between(test_subset.index, test_subset.lower_bounds, test_subset.upper_bounds, color=\"gray\", alpha=0.5, \n",
    "                 label=\"Benchmark Estimation Interval\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.title(\"2017-12-06: Real vs Benchmark\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf39681a12d5902f489aa36c08fcb4d0cc6d3246489205bad4407c57ca1a964d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
